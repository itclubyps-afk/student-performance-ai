# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xcL1ge4XfeS4j-QqMwRayFBsWe2E6eeO
"""

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

# ===============================
# CONFIG
# ===============================
SUBJECTS = ["Math", "Science", "English", "SST", "Hindi"]
np.random.seed(42)

st.set_page_config(
    page_title="AI Academic Performance System",
    layout="wide"
)

st.title("ðŸ“˜ AI-Based Academic Performance & Board Readiness System")

# ===============================
# DATA GENERATION
# ===============================
@st.cache_data
def generate_students(n=40):
    students = []
    for i in range(1, n + 1):
        base = np.random.randint(30, 50) if i % 10 == 0 else np.random.randint(50, 70)
        student = {"ID": i}

        student["Class9"] = {s: base + np.random.randint(-5, 5) for s in SUBJECTS}
        student["Term1"]  = {s: base + np.random.randint(0, 10) for s in SUBJECTS}
        student["Term2"]  = {s: base + np.random.randint(5, 15) for s in SUBJECTS}
        student["Term3"]  = {s: base + np.random.randint(0, 25) for s in SUBJECTS}

        students.append(student)
    return students

# ===============================
# FEATURE FUNCTIONS
# ===============================
def avg(term):
    return np.mean(list(term.values()))

def learning_velocity(s):
    return avg(s["Term3"]) - avg(s["Class9"])

def consistency_variance(s):
    terms = [avg(s[t]) for t in ["Class9", "Term1", "Term2", "Term3"]]
    return np.var(terms)

def confidence_index(s):
    return round(max(0, 100 - consistency_variance(s)), 2)

# ===============================
# DATASET + MODEL
# ===============================
def build_dataset(students):
    X, y = [], []
    for s in students:
        X.append([
            avg(s["Class9"]),
            avg(s["Term1"]),
            avg(s["Term2"]),
            avg(s["Term3"]),
            learning_velocity(s),
            consistency_variance(s)
        ])
        y.append(avg(s["Term3"]) + np.random.normal(0, 3))
    return np.array(X), np.array(y)

@st.cache_resource
def train_model(students):
    X, y = build_dataset(students)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    model = LinearRegression()
    model.fit(X_scaled, y)
    return model, scaler

# ===============================
# INTERPRETATION FUNCTIONS
# ===============================
def explain_velocity(v):
    if v < 5:
        return "Very slow improvement. Structured support recommended."
    elif v < 10:
        return "Moderate improvement. Progress visible but reinforcement needed."
    elif v < 20:
        return "Strong learning growth. Strategy effective."
    else:
        return "Exceptional improvement. Student learning efficiently."

def explain_consistency(c):
    if c < 60:
        return "Highly consistent performance across terms."
    elif c < 80:
        return "Mostly consistent with minor fluctuations."
    else:
        return "Performance shows fluctuations; monitor closely."

def performance_band(score):
    if score < 60:
        return "Critical Risk"
    elif score < 70:
        return "At Risk"
    elif score < 80:
        return "Stable Performer"
    elif score < 90:
        return "Strong Performer"
    else:
        return "Exceptional Performer"

def board_readiness(pred):
    return round(min(100, pred), 2)

def explain_board_readiness(val):
    if val < 50:
        return "Not board-ready: Intensive support needed for weak subjects."
    elif val < 66:
        return "At Risk: Focused improvement needed in weak areas."
    elif val < 76:
        return "Partially ready: Maintain consistent effort and revision."
    elif val < 91:
        return "Mostly ready: Continue exam practice and consistency."
    else:
        return "Fully ready: Student is exam-ready with top-level mastery."

def intervention_priority(pred, vel, conf):
    return round(max(0, (75 - pred)*1.2 + (10 - vel)*2 + (100 - conf)*0.3), 2)

# ===============================
# LOAD DATA
# ===============================
students = generate_students()
model, scaler = train_model(students)
X, _ = build_dataset(students)
preds = model.predict(scaler.transform(X))

# ===============================
# TEACHER DASHBOARD
# ===============================
st.header("ðŸ‘©â€ðŸ« TEACHER DASHBOARD")

if st.button("ðŸ“Š View Entire Class Performance"):

    rows = []
    weak_subjects_dict = {sub: [] for sub in SUBJECTS}
    class_avg = {sub: np.mean([s["Term3"][sub] for s in students]) for sub in SUBJECTS}

    for s, p in zip(students, preds):
        vel = learning_velocity(s)
        conf = confidence_index(s)
        ips = intervention_priority(p, vel, conf)

        gaps = {sub: class_avg[sub] - s["Term3"][sub] for sub in SUBJECTS}
        weak_subjects = []

        for sub, g in gaps.items():
            if g > 10:
                weak_subjects.append(sub)
                weak_subjects_dict[sub].append((s["ID"], "HIGH"))
            elif g > 5:
                weak_subjects.append(sub)
                weak_subjects_dict[sub].append((s["ID"], "MEDIUM"))

        rows.append({
            "ID": s["ID"],
            "Predicted Score": round(p, 2),
            "Category": performance_band(p),
            "Weak Subjects": ", ".join(weak_subjects) if weak_subjects else "None",
            "Intervention Score": ips,
            "Needs Attention": "YES" if ips > 25 or p < 70 else "NO"
        })

    df_teacher = pd.DataFrame(rows).sort_values("Intervention Score", ascending=False)
    st.dataframe(df_teacher, use_container_width=True)

    # ===============================
    # SUBJECT-WISE TABS (BEST & CLEANEST)
    # ===============================
    st.subheader("ðŸ“Œ SUBJECT-WISE WEAK STUDENTS (Teacher Actionable)")

    tabs = st.tabs(SUBJECTS)

    for tab, sub in zip(tabs, SUBJECTS):
        with tab:
            lst = weak_subjects_dict[sub]
            if lst:
                st.table(pd.DataFrame(lst, columns=["Student ID", "Priority"]))
            else:
                st.success("No weak students in this subject.")

# ===============================
# STUDENT DASHBOARD
# ===============================
st.header("ðŸŽ“ STUDENT AI DASHBOARD")

sid = st.selectbox("Select Student ID", [s["ID"] for s in students])

if st.button("ðŸ“˜ Generate AI Academic Performance Report"):

    student = next(s for s in students if s["ID"] == sid)
    idx = sid - 1
    pred = round(preds[idx], 2)

    vel = round(learning_velocity(student), 2)
    conf = confidence_index(student)

    df_rank = pd.DataFrame({
        "ID": [s["ID"] for s in students],
        "Score": preds
    }).sort_values("Score", ascending=False).reset_index(drop=True)

    rank = df_rank[df_rank["ID"] == sid].index[0] + 1
    percentile = round((1 - (rank - 1) / len(df_rank)) * 100, 2)

    readiness = board_readiness(pred)

    st.markdown("---")
    st.markdown(f"## ðŸ§¾ AI ACADEMIC PERFORMANCE REPORT â€” STUDENT {sid}")
    st.markdown("---")

    st.markdown("### ðŸ“˜ OVERALL STATUS")
    st.write(f"Predicted Board Score : {pred}")
    st.write(f"Performance Category  : {performance_band(pred)}")
    st.write(f"Class Rank / Percentile : {rank} / {percentile}%")

    st.markdown("### ðŸ“ˆ LEARNING BEHAVIOUR ANALYSIS")
    st.write(f"Academic Growth (Velocity) : {vel}")
    st.write(f"Interpretation             : {explain_velocity(vel)}")

    st.markdown("### ðŸ“Š CONSISTENCY ANALYSIS")
    st.write(f"Consistency Score          : {conf}")
    st.write(f"Interpretation             : {explain_consistency(conf)}")

    st.markdown("### ðŸŽ¯ BOARD READINESS")
    st.write(f"Board Readiness Index      : {readiness} / 100")
    st.write(f"Interpretation             : {explain_board_readiness(readiness)}")
    st.write("Suggested Actions:")
    if readiness < 50:
        st.write("â€¢ Intensive coaching and weekly practice for weak subjects.")
    elif readiness < 66:
        st.write("â€¢ Focused improvement on weak subjects and consistent revision.")
    elif readiness < 76:
        st.write("â€¢ Maintain consistent effort and revision.")
    elif readiness < 91:
        st.write("â€¢ Continue exam practice and maintain consistency.")
    else:
        st.write("â€¢ Maintain effort and exam strategy; top-level mastery practice.")

    st.markdown("### ðŸ“š SUBJECT-WISE INSIGHT")
    class_avg = {sub: np.mean([s2["Term3"][sub] for s2 in students]) for sub in SUBJECTS}
    gaps = {sub: class_avg[sub] - student["Term3"][sub] for sub in SUBJECTS}

    weak_subjects = []
    for sub, g in sorted(gaps.items(), key=lambda x: x[1], reverse=True):
        if g > 0:
            weak_subjects.append(sub)
            priority = "HIGH" if g > 10 else "MEDIUM"
            st.write(f"{sub}: Below class average â†’ Needs attention (Priority: {priority})")
        else:
            st.write(f"{sub}: Above class average â†’ Strength")

    st.markdown("### ðŸ§  PERSONALIZED AI ACTION PLAN")
    if weak_subjects:
        st.write(f"â€¢ Focus on {', '.join(weak_subjects[:2])} for next 6â€“8 weeks")
    else:
        st.write("â€¢ No weak subjects identified; focus on exam strategy and practice")
    st.write("â€¢ Weekly mock tests & error analysis")
    st.write("â€¢ Maintain consistent revision schedule")

    st.markdown("### ðŸ“ˆ Academic Growth Trend")
    terms = ["Class9", "Term1", "Term2", "Term3"]
    values = [avg(student[t]) for t in terms]
    fig, ax = plt.subplots()
    ax.plot(terms, values, marker="o")
    ax.grid(True)
    st.pyplot(fig)